{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543cf45a",
   "metadata": {},
   "source": [
    "# 1. Notebook Setup\n",
    "# Title, assignment info, and markdown overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "044f2c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "import csv\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "48957c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file_path = \"data/Mappings.csv\"\n",
    "employees_file_path = \"data/Employee.csv\"\n",
    "tasks_file_path = \"data/Tasks.csv\"\n",
    "rd.seed(20)\n",
    "\n",
    "# Data Classes\n",
    "class Task:\n",
    "    time:int =0\n",
    "    difficulty:int =0\n",
    "    deadline:int = 0\n",
    "    required_skill:str = ''\n",
    "    def __str__(self):\n",
    "        return f\"T Time:{self.time} Difficulty:{self.difficulty} Deadline:{self.deadline} requiredSkill:{self.required_skill}\"\n",
    "\n",
    "class Employee:\n",
    "    available_hours:int = 0\n",
    "    skill_level:int = 4\n",
    "    skills:list[str]=['']\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"E AH:{self.available_hours} Skill-Level:{self.skill_level} Skills:{self.skills}\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7ea3c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O\n",
    "\"\"\"\n",
    "Task csv:\n",
    "\n",
    "'ID', 'Time (hrs)', 'Difficulty', 'Deadline (hrs)', 'Required Skill'\n",
    "\n",
    "Employee csv:\n",
    "'Employee ID', 'Available Hrs', 'Skill Level', 'Skills'\n",
    "\n",
    "\n",
    "Using an adjancey list instead of an adjacney matrix!\n",
    "\n",
    "Since the input vector is 10 mappings x 11 features. Including a unique assignment penalty is redundant since a task mapped to 2 employees will create (10+1) mappings which doesn't work for the network input layer!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    num_of_tasks =10\n",
    "    num_of_employees = 5\n",
    "    tasks:list[Task]=[]\n",
    "    employees:list[Employee]=[]\n",
    "    \n",
    "    def load_tasks(self,fileName=tasks_file_path):\n",
    "        tasks =[]\n",
    "        with open(fileName,'r') as csvfile:\n",
    "            taskReader = csv.reader(csvfile)\n",
    "            next(taskReader)\n",
    "            for taskArr in taskReader:\n",
    "                newT = Task()\n",
    "                newT.time=int(taskArr[1])\n",
    "                newT.difficulty= int(taskArr[2])\n",
    "                newT.deadline = int(taskArr[3])\n",
    "                newT.required_skill= taskArr[4]\n",
    "                tasks.append(newT)\n",
    "        self.tasks= tasks\n",
    "\n",
    "    def load_employees(self,fileName=employees_file_path):\n",
    "        employees=[]\n",
    "        with open(fileName,'r') as csvfile:\n",
    "            employeeReader = csv.reader(csvfile)\n",
    "            next(employeeReader)\n",
    "            for employeeArr in employeeReader:\n",
    "                newEmployee = Employee()\n",
    "                newEmployee.available_hours=int(employeeArr[1])\n",
    "                newEmployee.skill_level= int(employeeArr[2])\n",
    "                skills = employeeArr[3].split(',')\n",
    "                newEmployee.skills = skills\n",
    "                employees.append(newEmployee)\n",
    "        self.employees = employees\n",
    "    def loadAll(self):\n",
    "        self.load_employees()\n",
    "        self.load_tasks()\n",
    "    \n",
    "\n",
    "\n",
    "class MappingHandler:\n",
    "    def __init__(self,tasks:list[Task],employees:list[Employee],num_of_mappings=100):\n",
    "        self.tasks:list[Task]= tasks\n",
    "        self.employees:list[Employee] = employees\n",
    "        self.num_of_mappings = num_of_mappings\n",
    "        self.mappings = []\n",
    "        self.costs=[]\n",
    "\n",
    "\n",
    "    def __costFunction(self,Mapping:list[int]):\n",
    "        w=0.2\n",
    "        overload = 0\n",
    "        skill_mismatch = 0\n",
    "        difficulty_violation = 0\n",
    "        deadline_violation = 0\n",
    "        unique_assignment = 0\n",
    "        employee_task_adj_list:list[list[Task]]=[[] for _ in range(len(self.employees))]\n",
    "\n",
    "        for i in range(len(Mapping)):\n",
    "            taskId=i\n",
    "\n",
    "            task = self.tasks[taskId]\n",
    "            num_of_employees_assigned = 0\n",
    "            employeeId = Mapping[i]\n",
    "            num_of_employees_assigned+=1\n",
    "            employee = self.employees[employeeId]\n",
    "            employee_task_adj_list[employeeId].append(task)\n",
    "            # skill mismatch violation\n",
    "            if task.required_skill not in employee.skills:\n",
    "                skill_mismatch+=1\n",
    "            if task.difficulty> employee.skill_level:\n",
    "                difficulty_violation+= 1\n",
    "            unique_assignment+= max(0,num_of_employees_assigned-1)\n",
    "\n",
    "\n",
    "\n",
    "        for employeeId in range(len(employee_task_adj_list)):\n",
    "            employee = self.employees[employeeId]\n",
    "            sortedEmployeeTasks = employee_task_adj_list[employeeId]\n",
    "            sortedEmployeeTasks.sort(key= lambda x:x.time)\n",
    "            sumHours=0\n",
    "            finishTime=0\n",
    "            for t in sortedEmployeeTasks:\n",
    "                sumHours+=t.time\n",
    "                finishTime+= t.time\n",
    "                deadline_violation+= max(0,finishTime - t.deadline)\n",
    "            overload+= max(0,sumHours- employee.available_hours) \n",
    "        total_penalty = overload+skill_mismatch+unique_assignment+deadline_violation+ difficulty_violation\n",
    "        return round(total_penalty*w,3)\n",
    "    def __reset(self):\n",
    "        self.mappings=[]\n",
    "        self.costs=[]\n",
    "\n",
    "\n",
    "    def generateMappings(self):\n",
    "        unique = set()\n",
    "        self.__reset()\n",
    "        while len(unique) < self.num_of_mappings:\n",
    "            mapping:list[int] = [0 for _ in self.tasks]         # Create a mapping for each iteration. Using an adjlist format\n",
    "            # possible_assignments = [i for i in range(len(employees))]  #list of possible assignments\n",
    "            for taskId in range(len(self.tasks)):\n",
    "                rand_employee =rd.randint(0,len(self.employees)-1)\n",
    "                mapping[taskId]=rand_employee\n",
    "            string = str(mapping)\n",
    "            if string not in unique: # ensure no duplicates in data generation\n",
    "                unique.add(string)\n",
    "                self.mappings.append(mapping)\n",
    "                self.costs.append(self.__costFunction(mapping))\n",
    "    \n",
    "\n",
    "    def readCSV(self,fileName=mapping_file_path):\n",
    "        self.__reset()\n",
    "        with open(fileName,'r') as csvfile:\n",
    "            mappingReader = csv.reader(csvfile)\n",
    "            next(mappingReader)\n",
    "            for line in mappingReader:\n",
    "                newMapping:list[int]=[]\n",
    "                for v in line:\n",
    "                    if v.isdigit():\n",
    "                        newMapping.append(int(v))\n",
    "                    else:\n",
    "                        self.costs.append(float(v))\n",
    "\n",
    "                self.mappings.append(newMapping)\n",
    "\n",
    "\n",
    "    def writeCSV(self,filepath =mapping_file_path):\n",
    "        with open(filepath,'w',newline='') as csvfile:\n",
    "                mappingWriter = csv.writer(csvfile)\n",
    "                mappingWriter.writerow([\"T1\",'T2','T3','T4','T5','T6','T7','T8','T9','T10','Penalty'])\n",
    "                mappingWriter.writerows(self.mappings)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def testDataGen():\n",
    "    dl = DataLoader()\n",
    "    dl.loadAll()\n",
    "    mappingloader = MappingHandler(dl.tasks,dl.employees)\n",
    "    mappingloader.generateMappings()\n",
    "    mappingloader.writeCSV('data/Mappings.csv')\n",
    "\n",
    "\n",
    "testDataGen()\n",
    "\n",
    "\n",
    "# def TestDataGen():\n",
    "\n",
    "#     all_mappings = mappingGenerator(task,employees)\n",
    "#     for mapping in all_mappings:\n",
    "#         cost = costFunction(mapping,task,employees)\n",
    "#         print(cost)\n",
    "\n",
    "# def verifyCost():\n",
    "#     mapping=[[2],[3],[1],[4],[2],[5],[1],[3],[5],[4]]\n",
    "    \n",
    "#     for i in range(len(mapping)):\n",
    "#         mapping[i][0]-=1\n",
    "#     employees,tasks = DataLoader().loadAll()\n",
    "#     # for t in tasks:\n",
    "#     #     print(t)\n",
    "    \n",
    "#     for e in employees:\n",
    "#         print(e)\n",
    "#     print(costFunction(mapping,tasks,employees))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18263f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 110)\n",
      "    0    1    2    3    4    5    6    7    8    9    ...  100  101  102  103  \\\n",
      "0     4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
      "1     4    3    8    1    0    0    8    3    1    0  ...    4   11    0    0   \n",
      "2     4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
      "3     4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
      "4     4    3    8    1    0    0   15    7    0    1  ...    4   11    0    0   \n",
      "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "65    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
      "66    4    3    8    1    0    0   12    6    1    1  ...    4   11    0    0   \n",
      "67    4    3    8    1    0    0    8    3    1    0  ...    4   11    0    0   \n",
      "68    4    3    8    1    0    0   15    7    0    1  ...    4   11    0    0   \n",
      "69    4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
      "\n",
      "    104  105  106  107  108  109  \n",
      "0     1   12    6    1    1    1  \n",
      "1     1   12    6    1    1    1  \n",
      "2     1   10    4    1    0    1  \n",
      "3     1   10    4    1    0    1  \n",
      "4     1   15    7    0    1    1  \n",
      "..  ...  ...  ...  ...  ...  ...  \n",
      "65    1   10    4    1    0    1  \n",
      "66    1    8    3    1    0    0  \n",
      "67    1    8    3    1    0    0  \n",
      "68    1    9    5    1    0    1  \n",
      "69    1    8    3    1    0    0  \n",
      "\n",
      "[70 rows x 110 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    0    1    2    3    4    5    6    7    8    9    ...  100  101  102  103  \\\n",
       " 0     4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
       " 1     4    3    8    1    0    0    8    3    1    0  ...    4   11    0    0   \n",
       " 2     4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
       " 3     4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 4     4    3    8    1    0    0   15    7    0    1  ...    4   11    0    0   \n",
       " ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 65    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 66    4    3    8    1    0    0   12    6    1    1  ...    4   11    0    0   \n",
       " 67    4    3    8    1    0    0    8    3    1    0  ...    4   11    0    0   \n",
       " 68    4    3    8    1    0    0   15    7    0    1  ...    4   11    0    0   \n",
       " 69    4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
       " \n",
       "     104  105  106  107  108  109  \n",
       " 0     1   12    6    1    1    1  \n",
       " 1     1   12    6    1    1    1  \n",
       " 2     1   10    4    1    0    1  \n",
       " 3     1   10    4    1    0    1  \n",
       " 4     1   15    7    0    1    1  \n",
       " ..  ...  ...  ...  ...  ...  ...  \n",
       " 65    1   10    4    1    0    1  \n",
       " 66    1    8    3    1    0    0  \n",
       " 67    1    8    3    1    0    0  \n",
       " 68    1    9    5    1    0    1  \n",
       " 69    1    8    3    1    0    0  \n",
       " \n",
       " [70 rows x 110 columns],\n",
       "     0    1    2    3    4    5    6    7    8    9    ...  100  101  102  103  \\\n",
       " 70    4    3    8    1    0    0   12    6    1    1  ...    4   11    0    0   \n",
       " 71    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 72    4    3    8    1    0    0   15    7    0    1  ...    4   11    0    0   \n",
       " 73    4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
       " 74    4    3    8    1    0    0   15    7    0    1  ...    4   11    0    0   \n",
       " 75    4    3    8    1    0    0   12    6    1    1  ...    4   11    0    0   \n",
       " 76    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 77    4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
       " 78    4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
       " 79    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 80    4    3    8    1    0    0   12    6    1    1  ...    4   11    0    0   \n",
       " 81    4    3    8    1    0    0    8    3    1    0  ...    4   11    0    0   \n",
       " 82    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 83    4    3    8    1    0    0   12    6    1    1  ...    4   11    0    0   \n",
       " 84    4    3    8    1    0    0   12    6    1    1  ...    4   11    0    0   \n",
       " \n",
       "     104  105  106  107  108  109  \n",
       " 70    1    9    5    1    0    1  \n",
       " 71    1   12    6    1    1    1  \n",
       " 72    1    9    5    1    0    1  \n",
       " 73    1   15    7    0    1    1  \n",
       " 74    1   10    4    1    0    1  \n",
       " 75    1    9    5    1    0    1  \n",
       " 76    1    8    3    1    0    0  \n",
       " 77    1   15    7    0    1    1  \n",
       " 78    1    9    5    1    0    1  \n",
       " 79    1    8    3    1    0    0  \n",
       " 80    1    9    5    1    0    1  \n",
       " 81    1   12    6    1    1    1  \n",
       " 82    1    9    5    1    0    1  \n",
       " 83    1   15    7    0    1    1  \n",
       " 84    1   10    4    1    0    1  \n",
       " \n",
       " [15 rows x 110 columns],\n",
       "     0    1    2    3    4    5    6    7    8    9    ...  100  101  102  103  \\\n",
       " 85    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 86    4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
       " 87    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 88    4    3    8    1    0    0   12    6    1    1  ...    4   11    0    0   \n",
       " 89    4    3    8    1    0    0   15    7    0    1  ...    4   11    0    0   \n",
       " 90    4    3    8    1    0    0    8    3    1    0  ...    4   11    0    0   \n",
       " 91    4    3    8    1    0    0   15    7    0    1  ...    4   11    0    0   \n",
       " 92    4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
       " 93    4    3    8    1    0    0    8    3    1    0  ...    4   11    0    0   \n",
       " 94    4    3    8    1    0    0   15    7    0    1  ...    4   11    0    0   \n",
       " 95    4    3    8    1    0    0    8    3    1    0  ...    4   11    0    0   \n",
       " 96    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 97    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 98    4    3    8    1    0    0   10    4    1    0  ...    4   11    0    0   \n",
       " 99    4    3    8    1    0    0    9    5    1    0  ...    4   11    0    0   \n",
       " \n",
       "     104  105  106  107  108  109  \n",
       " 85    1   15    7    0    1    1  \n",
       " 86    1   10    4    1    0    1  \n",
       " 87    1    9    5    1    0    1  \n",
       " 88    1    9    5    1    0    1  \n",
       " 89    1    9    5    1    0    1  \n",
       " 90    1    8    3    1    0    0  \n",
       " 91    1    9    5    1    0    1  \n",
       " 92    1   12    6    1    1    1  \n",
       " 93    1   12    6    1    1    1  \n",
       " 94    1    9    5    1    0    1  \n",
       " 95    1    8    3    1    0    0  \n",
       " 96    1   10    4    1    0    1  \n",
       " 97    1    9    5    1    0    1  \n",
       " 98    1   12    6    1    1    1  \n",
       " 99    1   15    7    0    1    1  \n",
       " \n",
       " [15 rows x 110 columns])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Preprocessing\n",
    "# returns a 3-element vector\n",
    "def one_hot_encode_skill(skillsVector):\n",
    "    skills= ['A','B','C']\n",
    "    hot_encoding=[]\n",
    "    j=0\n",
    "    for i in range(len(skills)):\n",
    "        if j< len(skillsVector)and  skills[i] == skillsVector[j]:\n",
    "            j+=1\n",
    "            hot_encoding.append(1)\n",
    "        else:\n",
    "            hot_encoding.append(0)\n",
    "    return hot_encoding\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def construct_input_vector(mappingloader:MappingHandler):\n",
    "    featureVector = []\n",
    "\n",
    "    for mp in mappingloader.mappings:\n",
    "        vector=[]\n",
    "        for i in range(len(mp)):\n",
    "\n",
    "            task = mappingloader.tasks[i]\n",
    "            employee = mappingloader.employees[mp[i]]\n",
    "            vector.extend([task.time,task.difficulty,task.deadline])\n",
    "            vector.extend(one_hot_encode_skill(task.required_skill))\n",
    "            vector.extend([employee.available_hours,employee.skill_level])\n",
    "            vector.extend(one_hot_encode_skill( employee.skills))\n",
    "        featureVector.append(vector)\n",
    "        \n",
    "    df = pd.DataFrame(featureVector)\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "def split_data(df):\n",
    "    df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    train_size = int(0.7 * len(df_shuffled))\n",
    "    val_size = int(0.15 * len(df_shuffled))\n",
    "    test_size = len(df_shuffled) - train_size - val_size\n",
    "    train_df = df_shuffled[:train_size]\n",
    "    val_df = df_shuffled[train_size:train_size + val_size]\n",
    "    test_df = df_shuffled[train_size + val_size:]\n",
    "    return train_df,val_df,test_df\n",
    "\n",
    "def pre_process():\n",
    "    dl = DataLoader()\n",
    "    dl.loadAll()\n",
    "    mappingloader = MappingHandler(dl.tasks,dl.employees)\n",
    "    mappingloader.readCSV('data/Mappings.csv')\n",
    "    df = construct_input_vector(mappingloader)\n",
    "    return split_data(df)\n",
    "\n",
    "# pre_process()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414f885",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '’' (U+2019) (3784911823.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[57], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    def __init__(self, layer_dims, activation=’relu’):\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '’' (U+2019)\n"
     ]
    }
   ],
   "source": [
    "# 5. Model Definitions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwrokArgs:\n",
    "    layer_dims=[]\n",
    "    name=''\n",
    "    activation=''\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_dims:list[int],name, activation='relu'):\n",
    "        self.name = name\n",
    "        self.input_size = layer_dims[0]\n",
    "        self.weights=np.array([])\n",
    "        self.biases=np.array([])\n",
    "        \n",
    "        for i in range(1,len(layer_dims)):\n",
    "            self.weights= np.append(self.weights,np.random.randn(layer_dims[i],layer_dims[i-1]))*0.01\n",
    "            self.biases =np.append(self.biases,np.zeros((layer_dims[i],1)))\n",
    "        \n",
    "\n",
    "        self.layer_dims = layer_dims\n",
    "    def forward(self, x):\n",
    "        \n",
    "\n",
    "    def backward(self, x, y_true):\n",
    "        pass\n",
    "\n",
    "    def update_params(self, lr):\n",
    "        pass\n",
    "\n",
    "    # 6. Training Loop\n",
    "    def train(model, X_train, y_train, params):\n",
    "        pass\n",
    "    # implement mini-batch SGD, record loss\n",
    "\n",
    "# 7. Evaluation & Plots\n",
    "#- Generate the eight required figures\n",
    "#- Save each via plt.savefig()\n",
    "# 8. Save & Export\n",
    "#- Download figures\n",
    "#- Optionally, pickle model parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
